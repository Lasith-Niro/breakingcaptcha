number of batches: 157
sum of samples trained 39250
loss after epoch 1 = 2.801796: 
train accuracy after epoch 1 = 0.430726: 
-----------------------------------

sum of samples trained 39250
loss after epoch 2 = 0.137049: 
train accuracy after epoch 2 = 0.746634: 
-----------------------------------

sum of samples trained 39250
loss after epoch 3 = 0.100879: 
train accuracy after epoch 3 = 0.827144: 
-----------------------------------

sum of samples trained 39250
loss after epoch 4 = 0.079491: 
train accuracy after epoch 4 = 0.870624: 
-----------------------------------

sum of samples trained 39250
loss after epoch 5 = 0.065495: 
train accuracy after epoch 5 = 0.897233: 
-----------------------------------

sum of samples trained 39250
loss after epoch 6 = 0.056661: 
train accuracy after epoch 6 = 0.912963: 
-----------------------------------

sum of samples trained 39250
loss after epoch 7 = 0.049504: 
train accuracy after epoch 7 = 0.924428: 
-----------------------------------

sum of samples trained 39250
loss after epoch 8 = 0.043108: 
train accuracy after epoch 8 = 0.936005: 
-----------------------------------

sum of samples trained 39250
loss after epoch 9 = 0.039162: 
train accuracy after epoch 9 = 0.942762: 
-----------------------------------

sum of samples trained 39250
loss after epoch 10 = 0.035533: 
train accuracy after epoch 10 = 0.948652: 
-----------------------------------

done training
True   | Predicted
48036  |48036     
72763  |72763     
78472  |78472     
51326  |51326     
10256  |10256     
96789  |96789     
61356  |61356     
81852  |81852     
71679  |71679     
80473  |80473     
75617  |75617     
77087  |77087     
02332  |02332     
39846  |39846     
99539  |99539     
33951  |33951     
01957  |01957     
00863  |00863     
47759  |47759     
83309  |83309     
60803  |60803     
99092  |99092     
19998  |19998     
92865  |92865     
08088  |08088     
82290  |82298     
08339  |08339     
90289  |90289     
87855  |87855     
81977  |81977     
37228  |37228     
44333  |44333     
15518  |15518     
58563  |58563     
68403  |68403     
48592  |48592     
65929  |65929     
92709  |92709     
33606  |33606     
18850  |18850     
58243  |58243     
04711  |04711     
85369  |85369     
27307  |27307     
04026  |04026     
00639  |00639     
12766  |12766     
32765  |32765     
09786  |09786     
00409  |00409     
49613  |49610     
54563  |54563     
94571  |94571     
93269  |93269     
67442  |67442     
31149  |31149     
39951  |39951     
30875  |30875     
09241  |09241     
01138  |01138     
94650  |94650     
47589  |47589     
43951  |43951     
82053  |82053     
69988  |69988     
45070  |45073     
50870  |50870     
88758  |88750     
42820  |42820     
54344  |54344     
44298  |44298     
34892  |34892     
92802  |92802     
08940  |08940     
02967  |02967     
61275  |61275     
64380  |64380     
51368  |51368     
50872  |50872     
04426  |04426     
81550  |81550     
45951  |45951     
23687  |23687     
70111  |70111     
18006  |18006     
87278  |87278     
98022  |98022     
81231  |81231     
77550  |77550     
01615  |01615     
87251  |87251     
66454  |66454     
37030  |37030     
55116  |55116     
67650  |67650     
91469  |91469     
03735  |03735     
06515  |06515     
99322  |99322     
18333  |18333     
printing correct predictions
done testing
Test Accuracy 0.992
